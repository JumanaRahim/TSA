{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOCiHV5rWUlKbQuadrzmvc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JumanaRahim/TSA/blob/main/WLT_JSRT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQl1YXMLWg1E",
        "outputId": "e5743d36-e396-4644-fc82-b6ac3f2bd4b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Lambda\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Activation\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import concatenate\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import plot_model\n",
        "import pandas as pd                     \n",
        "import matplotlib.pyplot as plt          # plotting\n",
        "import numpy as np                       # dense matrices\n",
        "from scipy.sparse import csr_matrix      # sparse matrices\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "0kN_p2spWptQ"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "data_set_path = '/content/drive/MyDrive/dataset_jumana/dataset (1)'\n",
        "os.listdir(data_set_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4fSX5Jz5Dj0",
        "outputId": "02858df3-2cab-497e-b924-a0e5632786f8"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'test']"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_gen = ImageDataGenerator(\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_data_gen = ImageDataGenerator()\n",
        "train_img_dir = '/content/drive/MyDrive/dataset_jumana/dataset (1)/train'\n",
        "val_img_dir   = '/content/drive/MyDrive/dataset_jumana/dataset (1)/test'\n",
        "# train & test generators\n",
        "train_generator = train_data_gen.flow_from_directory(\n",
        "    train_img_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=8,\n",
        "    class_mode='binary')\n",
        "\n",
        "val_generator = val_data_gen.flow_from_directory(\n",
        "    val_img_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=8,\n",
        "    class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GllEIyVm5N50",
        "outputId": "965b2e57-f398-4d38-c489-eba080f2ac89"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 115 images belonging to 2 classes.\n",
            "Found 39 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new data generator with augmentation\n",
        "train_data_gen_aug = ImageDataGenerator(\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# create a generator for the augmented training data\n",
        "train_generator_aug = train_data_gen_aug.flow_from_directory(\n",
        "    '/content/drive/MyDrive/dataset_jumana/dataset (1)/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=8,\n",
        "    class_mode='binary')\n",
        "\n",
        "# get the total number of augmented images generated\n",
        "total_augmented_images = (train_generator_aug.n * 8) # multiply with batch size\n",
        "\n",
        "print(\"Total number of augmented images: \", total_augmented_images)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGab7NYR6_mG",
        "outputId": "3538b52f-bdc3-41e2-c531-cf89fbee23b0"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 115 images belonging to 2 classes.\n",
            "Total number of augmented images:  920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a generator for the augmented validation data\n",
        "val_generator_aug = val_data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/dataset_jumana/dataset (1)/test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=8,\n",
        "    class_mode='binary')\n",
        "\n",
        "# get the total number of augmented images generated\n",
        "total_augmented_images = (val_generator_aug.n * 8) # multiply with batch size\n",
        "\n",
        "print(\"Total number of augmented images: \", total_augmented_images)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b-h0cTV8atw",
        "outputId": "74a8851e-eea5-435c-e705-f05fe0b62944"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 39 images belonging to 2 classes.\n",
            "Total number of augmented images:  312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pywt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FHZ0Rp3iK0Aj"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch operation usng tensor slice\n",
        "def WaveletTransformAxisY(batch_img):\n",
        "    odd_img  = batch_img[:,0::2]\n",
        "    even_img = batch_img[:,1::2]\n",
        "    L = (odd_img + even_img) / 2.0\n",
        "    H = K.abs(odd_img - even_img)\n",
        "    return L, H\n",
        "\n",
        "def WaveletTransformAxisX(batch_img):\n",
        "    # transpose + fliplr\n",
        "    tmp_batch = K.permute_dimensions(batch_img, [0, 2, 1])[:,:,::-1]\n",
        "    _dst_L, _dst_H = WaveletTransformAxisY(tmp_batch)\n",
        "    # transpose + flipud\n",
        "    dst_L = K.permute_dimensions(_dst_L, [0, 2, 1])[:,::-1,...]\n",
        "    dst_H = K.permute_dimensions(_dst_H, [0, 2, 1])[:,::-1,...]\n",
        "    return dst_L, dst_H"
      ],
      "metadata": {
        "id": "JPJS9yv0TMIS"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Wavelet(batch_image):\n",
        "    # make channel first image\n",
        "    batch_image = K.permute_dimensions(batch_image, [0, 3, 1, 2])\n",
        "    r = batch_image[:,0]\n",
        "    g = batch_image[:,1]\n",
        "    b = batch_image[:,2]\n",
        "\n",
        "    # level 1 decomposition\n",
        "    wavelet_L, wavelet_H = WaveletTransformAxisY(r)\n",
        "    r_wavelet_LL, r_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n",
        "    r_wavelet_HL, r_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n",
        "\n",
        "    wavelet_L, wavelet_H = WaveletTransformAxisY(g)\n",
        "    g_wavelet_LL, g_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n",
        "    g_wavelet_HL, g_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n",
        "\n",
        "    wavelet_L, wavelet_H = WaveletTransformAxisY(b)\n",
        "    b_wavelet_LL, b_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n",
        "    b_wavelet_HL, b_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n",
        "\n",
        "    wavelet_data = [r_wavelet_LL, r_wavelet_LH, r_wavelet_HL, r_wavelet_HH, \n",
        "                    g_wavelet_LL, g_wavelet_LH, g_wavelet_HL, g_wavelet_HH,\n",
        "                    b_wavelet_LL, b_wavelet_LH, b_wavelet_HL, b_wavelet_HH]\n",
        "    transform_batch = K.stack(wavelet_data, axis=1)\n",
        "\n",
        "    # level 2 decomposition\n",
        "    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(r_wavelet_LL)\n",
        "    r_wavelet_LL2, r_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n",
        "    r_wavelet_HL2, r_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n",
        "\n",
        "    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(g_wavelet_LL)\n",
        "    g_wavelet_LL2, g_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n",
        "    g_wavelet_HL2, g_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n",
        "\n",
        "    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(b_wavelet_LL)\n",
        "    b_wavelet_LL2, b_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n",
        "    b_wavelet_HL2, b_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n",
        "\n",
        "\n",
        "    wavelet_data_l2 = [r_wavelet_LL2, r_wavelet_LH2, r_wavelet_HL2, r_wavelet_HH2, \n",
        "                    g_wavelet_LL2, g_wavelet_LH2, g_wavelet_HL2, g_wavelet_HH2,\n",
        "                    b_wavelet_LL2, b_wavelet_LH2, b_wavelet_HL2, b_wavelet_HH2]\n",
        "    transform_batch_l2 = K.stack(wavelet_data_l2, axis=1)\n",
        "\n",
        "    # level 3 decomposition\n",
        "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(r_wavelet_LL2)\n",
        "    r_wavelet_LL3, r_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n",
        "    r_wavelet_HL3, r_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n",
        "\n",
        "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(g_wavelet_LL2)\n",
        "    g_wavelet_LL3, g_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n",
        "    g_wavelet_HL3, g_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n",
        "\n",
        "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(b_wavelet_LL2)\n",
        "    b_wavelet_LL3, b_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n",
        "    b_wavelet_HL3, b_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n",
        "\n",
        "    wavelet_data_l3 = [r_wavelet_LL3, r_wavelet_LH3, r_wavelet_HL3, r_wavelet_HH3, \n",
        "                    g_wavelet_LL3, g_wavelet_LH3, g_wavelet_HL3, g_wavelet_HH3,\n",
        "                    b_wavelet_LL3, b_wavelet_LH3, b_wavelet_HL3, b_wavelet_HH3]\n",
        "    transform_batch_l3 = K.stack(wavelet_data_l3, axis=1)\n",
        "\n",
        "   # level 4 decomposition\n",
        "    wavelet_L4, wavelet_H4 = WaveletTransformAxisY(r_wavelet_LL3)\n",
        "    r_wavelet_LL4, r_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n",
        "    r_wavelet_HL4, r_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n",
        "\n",
        "    wavelet_L4, wavelet_H4 = WaveletTransformAxisY(g_wavelet_LL3)\n",
        "    g_wavelet_LL4, g_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n",
        "    g_wavelet_HL4, g_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n",
        "\n",
        "    wavelet_L4, wavelet_H4 = WaveletTransformAxisY(b_wavelet_LL3)\n",
        "    b_wavelet_LL4, b_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n",
        "    b_wavelet_HL4, b_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n",
        "    wavelet_data_l4 = [r_wavelet_LL4, r_wavelet_LH4, r_wavelet_HL4, r_wavelet_HH4, \n",
        "                    g_wavelet_LL4, g_wavelet_LH4, g_wavelet_HL4, g_wavelet_HH4,\n",
        "                    b_wavelet_LL4, b_wavelet_LH4, b_wavelet_HL4, b_wavelet_HH4]\n",
        "    transform_batch_l4 = K.stack(wavelet_data_l4, axis=1)\n",
        "\n",
        "\n",
        "    # print('shape before')\n",
        "    # print(transform_batch.shape)\n",
        "    # print(transform_batch_l2.shape)\n",
        "    # print(transform_batch_l3.shape)\n",
        "    # print(transform_batch_l4.shape)\n",
        "\n",
        "    decom_level_1 = K.permute_dimensions(transform_batch, [0, 2, 3, 1])\n",
        "    decom_level_2 = K.permute_dimensions(transform_batch_l2, [0, 2, 3, 1])\n",
        "    decom_level_3 = K.permute_dimensions(transform_batch_l3, [0, 2, 3, 1])\n",
        "    decom_level_4 = K.permute_dimensions(transform_batch_l4, [0, 2, 3, 1])\n",
        "    \n",
        "    # print('shape after')\n",
        "    # print(decom_level_1.shape)\n",
        "    # print(decom_level_2.shape)\n",
        "    # print(decom_level_3.shape)\n",
        "    # print(decom_level_4.shape)\n",
        "    return [decom_level_1, decom_level_2, decom_level_3, decom_level_4]\n",
        "\n",
        "\n",
        "def Wavelet_out_shape(input_shapes):\n",
        "    # print('in to shape')\n",
        "    return [tuple([None, 112, 112, 12]), tuple([None, 56, 56, 12]), \n",
        "            tuple([None, 28, 28, 12]), tuple([None, 14, 14, 12])]\n",
        "     "
      ],
      "metadata": {
        "id": "25szHDY0TW82"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Lambda\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Activation\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import concatenate\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import plot_model\n",
        "def get_wavelet_cnn_model():\n",
        "\n",
        "    input_shape = 224, 224, 3\n",
        "\n",
        "    input_ = Input(input_shape, name='the_input')\n",
        "    # wavelet = Lambda(Wavelet, name='wavelet')\n",
        "    wavelet = Lambda(Wavelet, Wavelet_out_shape, name='wavelet')\n",
        "    input_l1, input_l2, input_l3, input_l4 = wavelet(input_)\n",
        "    # print(input_l1)\n",
        "    # print(input_l2)\n",
        "    # print(input_l3)\n",
        "    # print(input_l4)\n",
        "    # level one decomposition starts\n",
        "    conv_1 = Conv2D(64, kernel_size=(3, 3), padding='same', name='conv_1')(input_l1)\n",
        "    norm_1 = BatchNormalization(name='norm_1')(conv_1)\n",
        "    relu_1 = Activation('relu', name='relu_1')(norm_1)\n",
        "\n",
        "    conv_1_2 = Conv2D(64, kernel_size=(3, 3), strides=(2, 2), padding='same', name='conv_1_2')(relu_1)\n",
        "    norm_1_2 = BatchNormalization(name='norm_1_2')(conv_1_2)\n",
        "    relu_1_2 = Activation('relu', name='relu_1_2')(norm_1_2)\n",
        "\n",
        "    # level two decomposition starts\n",
        "    conv_a = Conv2D(filters=64, kernel_size=(3, 3), padding='same', name='conv_a')(input_l2)\n",
        "    norm_a = BatchNormalization(name='norm_a')(conv_a)\n",
        "    relu_a = Activation('relu', name='relu_a')(norm_a)\n",
        "\n",
        "    # concate level one and level two decomposition\n",
        "    concate_level_2 = concatenate([relu_1_2, relu_a])\n",
        "    conv_2 = Conv2D(128, kernel_size=(3, 3), padding='same', name='conv_2')(concate_level_2)\n",
        "    norm_2 = BatchNormalization(name='norm_2')(conv_2)\n",
        "    relu_2 = Activation('relu', name='relu_2')(norm_2)\n",
        "\n",
        "    conv_2_2 = Conv2D(128, kernel_size=(3, 3), strides=(2, 2), padding='same', name='conv_2_2')(relu_2)\n",
        "    norm_2_2 = BatchNormalization(name='norm_2_2')(conv_2_2)\n",
        "    relu_2_2 = Activation('relu', name='relu_2_2')(norm_2_2)\n",
        "\n",
        "    # level three decomposition starts \n",
        "    conv_b = Conv2D(filters=64, kernel_size=(3, 3), padding='same', name='conv_b')(input_l3)\n",
        "    norm_b = BatchNormalization(name='norm_b')(conv_b)\n",
        "    relu_b = Activation('relu', name='relu_b')(norm_b)\n",
        "\n",
        "    conv_b_2 = Conv2D(128, kernel_size=(3, 3), padding='same', name='conv_b_2')(relu_b)\n",
        "    norm_b_2 = BatchNormalization(name='norm_b_2')(conv_b_2)\n",
        "    relu_b_2 = Activation('relu', name='relu_b_2')(norm_b_2)\n",
        "\n",
        "    # concate level two and level three decomposition \n",
        "    concate_level_3 = concatenate([relu_2_2, relu_b_2])\n",
        "    conv_3 = Conv2D(256, kernel_size=(3, 3), padding='same', name='conv_3')(concate_level_3)\n",
        "    norm_3 = BatchNormalization(name='nomr_3')(conv_3)\n",
        "    relu_3 = Activation('relu', name='relu_3')(norm_3)\n",
        "\n",
        "    conv_3_2 = Conv2D(256, kernel_size=(3, 3), strides=(2, 2), padding='same', name='conv_3_2')(relu_3)\n",
        "    norm_3_2 = BatchNormalization(name='norm_3_2')(conv_3_2)\n",
        "    relu_3_2 = Activation('relu', name='relu_3_2')(norm_3_2)\n",
        "\n",
        "    # level four decomposition start\n",
        "    conv_c = Conv2D(64, kernel_size=(3, 3), padding='same', name='conv_c')(input_l4)\n",
        "    norm_c = BatchNormalization(name='norm_c')(conv_c)\n",
        "    relu_c = Activation('relu', name='relu_c')(norm_c)\n",
        "\n",
        "    conv_c_2 = Conv2D(256, kernel_size=(3, 3), padding='same', name='conv_c_2')(relu_c)\n",
        "    norm_c_2 = BatchNormalization(name='norm_c_2')(conv_c_2)\n",
        "    relu_c_2 = Activation('relu', name='relu_c_2')(norm_c_2)\n",
        "\n",
        "    conv_c_3 = Conv2D(256, kernel_size=(3, 3), padding='same', name='conv_c_3')(relu_c_2)\n",
        "    norm_c_3 = BatchNormalization(name='norm_c_3')(conv_c_3)\n",
        "    relu_c_3 = Activation('relu', name='relu_c_3')(norm_c_3)\n",
        "\n",
        "    # concate level level three and level four decomposition\n",
        "    concate_level_4 = concatenate([relu_3_2, relu_c_3])\n",
        "    conv_4 = Conv2D(256, kernel_size=(3, 3), padding='same', name='conv_4')(concate_level_4)\n",
        "    norm_4 = BatchNormalization(name='norm_4')(conv_4)\n",
        "    relu_4 = Activation('relu', name='relu_4')(norm_4)\n",
        "\n",
        "    conv_4_2 = Conv2D(256, kernel_size=(3, 3), strides=(2, 2), padding='same', name='conv_4_2')(relu_4)\n",
        "    norm_4_2 = BatchNormalization(name='norm_4_2')(conv_4_2)\n",
        "    relu_4_2 = Activation('relu', name='relu_4_2')(norm_4_2)\n",
        "\n",
        "    conv_5_1 = Conv2D(128, kernel_size=(3, 3), padding='same', name='conv_5_1')(relu_4_2)\n",
        "    norm_5_1 = BatchNormalization(name='norm_5_1')(conv_5_1)\n",
        "    relu_5_1 = Activation('relu', name='relu_5_1')(norm_5_1)\n",
        "\n",
        "    pool_5_1 = AveragePooling2D(pool_size=(7, 7), strides=1, padding='same', name='avg_pool_5_1')(relu_5_1)\n",
        "    flat_5_1 = Flatten(name='flat_5_1')(pool_5_1) \n",
        "\n",
        "    fc_5 = Dense(2048, name='fc_5')(flat_5_1)\n",
        "    norm_5 = BatchNormalization(name='norm_5')(fc_5)\n",
        "    relu_5 = Activation('relu', name='relu_5')(norm_5)\n",
        "    drop_5 = Dropout(0.5, name='drop_5')(relu_5)\n",
        "\n",
        "    fc_6 = Dense(2048, name='fc_6')(drop_5)\n",
        "    norm_6 = BatchNormalization(name='norm_6')(fc_6)\n",
        "    relu_6 = Activation('relu', name='relu_6')(norm_6)\n",
        "    drop_6 = Dropout(0.5, name='drop_6')(relu_6)\n",
        "\n",
        "    output = Dense(1, activation='softmax', name='fc_7')(drop_6)\n",
        "\n",
        "    model = Model(inputs=input_, outputs=output)\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "aY-L_euSU9W4"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_wavelet_cnn_model()"
      ],
      "metadata": {
        "id": "kAvBYesXVW54",
        "outputId": "1dcd64ff-8818-421d-e0aa-631c9a15559b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " the_input (InputLayer)         [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " wavelet (Lambda)               [(None, 112, 112, 1  0           ['the_input[0][0]']              \n",
            "                                2),                                                               \n",
            "                                 (None, 56, 56, 12)                                               \n",
            "                                , (None, 28, 28, 12                                               \n",
            "                                ),                                                                \n",
            "                                 (None, 14, 14, 12)                                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " conv_1 (Conv2D)                (None, 112, 112, 64  6976        ['wavelet[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " norm_1 (BatchNormalization)    (None, 112, 112, 64  256         ['conv_1[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " relu_1 (Activation)            (None, 112, 112, 64  0           ['norm_1[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv_1_2 (Conv2D)              (None, 56, 56, 64)   36928       ['relu_1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv_a (Conv2D)                (None, 56, 56, 64)   6976        ['wavelet[0][1]']                \n",
            "                                                                                                  \n",
            " norm_1_2 (BatchNormalization)  (None, 56, 56, 64)   256         ['conv_1_2[0][0]']               \n",
            "                                                                                                  \n",
            " norm_a (BatchNormalization)    (None, 56, 56, 64)   256         ['conv_a[0][0]']                 \n",
            "                                                                                                  \n",
            " relu_1_2 (Activation)          (None, 56, 56, 64)   0           ['norm_1_2[0][0]']               \n",
            "                                                                                                  \n",
            " relu_a (Activation)            (None, 56, 56, 64)   0           ['norm_a[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_18 (Concatenate)   (None, 56, 56, 128)  0           ['relu_1_2[0][0]',               \n",
            "                                                                  'relu_a[0][0]']                 \n",
            "                                                                                                  \n",
            " conv_2 (Conv2D)                (None, 56, 56, 128)  147584      ['concatenate_18[0][0]']         \n",
            "                                                                                                  \n",
            " conv_b (Conv2D)                (None, 28, 28, 64)   6976        ['wavelet[0][2]']                \n",
            "                                                                                                  \n",
            " norm_2 (BatchNormalization)    (None, 56, 56, 128)  512         ['conv_2[0][0]']                 \n",
            "                                                                                                  \n",
            " norm_b (BatchNormalization)    (None, 28, 28, 64)   256         ['conv_b[0][0]']                 \n",
            "                                                                                                  \n",
            " relu_2 (Activation)            (None, 56, 56, 128)  0           ['norm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " relu_b (Activation)            (None, 28, 28, 64)   0           ['norm_b[0][0]']                 \n",
            "                                                                                                  \n",
            " conv_2_2 (Conv2D)              (None, 28, 28, 128)  147584      ['relu_2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv_b_2 (Conv2D)              (None, 28, 28, 128)  73856       ['relu_b[0][0]']                 \n",
            "                                                                                                  \n",
            " norm_2_2 (BatchNormalization)  (None, 28, 28, 128)  512         ['conv_2_2[0][0]']               \n",
            "                                                                                                  \n",
            " norm_b_2 (BatchNormalization)  (None, 28, 28, 128)  512         ['conv_b_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv_c (Conv2D)                (None, 14, 14, 64)   6976        ['wavelet[0][3]']                \n",
            "                                                                                                  \n",
            " relu_2_2 (Activation)          (None, 28, 28, 128)  0           ['norm_2_2[0][0]']               \n",
            "                                                                                                  \n",
            " relu_b_2 (Activation)          (None, 28, 28, 128)  0           ['norm_b_2[0][0]']               \n",
            "                                                                                                  \n",
            " norm_c (BatchNormalization)    (None, 14, 14, 64)   256         ['conv_c[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_19 (Concatenate)   (None, 28, 28, 256)  0           ['relu_2_2[0][0]',               \n",
            "                                                                  'relu_b_2[0][0]']               \n",
            "                                                                                                  \n",
            " relu_c (Activation)            (None, 14, 14, 64)   0           ['norm_c[0][0]']                 \n",
            "                                                                                                  \n",
            " conv_3 (Conv2D)                (None, 28, 28, 256)  590080      ['concatenate_19[0][0]']         \n",
            "                                                                                                  \n",
            " conv_c_2 (Conv2D)              (None, 14, 14, 256)  147712      ['relu_c[0][0]']                 \n",
            "                                                                                                  \n",
            " nomr_3 (BatchNormalization)    (None, 28, 28, 256)  1024        ['conv_3[0][0]']                 \n",
            "                                                                                                  \n",
            " norm_c_2 (BatchNormalization)  (None, 14, 14, 256)  1024        ['conv_c_2[0][0]']               \n",
            "                                                                                                  \n",
            " relu_3 (Activation)            (None, 28, 28, 256)  0           ['nomr_3[0][0]']                 \n",
            "                                                                                                  \n",
            " relu_c_2 (Activation)          (None, 14, 14, 256)  0           ['norm_c_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv_3_2 (Conv2D)              (None, 14, 14, 256)  590080      ['relu_3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv_c_3 (Conv2D)              (None, 14, 14, 256)  590080      ['relu_c_2[0][0]']               \n",
            "                                                                                                  \n",
            " norm_3_2 (BatchNormalization)  (None, 14, 14, 256)  1024        ['conv_3_2[0][0]']               \n",
            "                                                                                                  \n",
            " norm_c_3 (BatchNormalization)  (None, 14, 14, 256)  1024        ['conv_c_3[0][0]']               \n",
            "                                                                                                  \n",
            " relu_3_2 (Activation)          (None, 14, 14, 256)  0           ['norm_3_2[0][0]']               \n",
            "                                                                                                  \n",
            " relu_c_3 (Activation)          (None, 14, 14, 256)  0           ['norm_c_3[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_20 (Concatenate)   (None, 14, 14, 512)  0           ['relu_3_2[0][0]',               \n",
            "                                                                  'relu_c_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv_4 (Conv2D)                (None, 14, 14, 256)  1179904     ['concatenate_20[0][0]']         \n",
            "                                                                                                  \n",
            " norm_4 (BatchNormalization)    (None, 14, 14, 256)  1024        ['conv_4[0][0]']                 \n",
            "                                                                                                  \n",
            " relu_4 (Activation)            (None, 14, 14, 256)  0           ['norm_4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv_4_2 (Conv2D)              (None, 7, 7, 256)    590080      ['relu_4[0][0]']                 \n",
            "                                                                                                  \n",
            " norm_4_2 (BatchNormalization)  (None, 7, 7, 256)    1024        ['conv_4_2[0][0]']               \n",
            "                                                                                                  \n",
            " relu_4_2 (Activation)          (None, 7, 7, 256)    0           ['norm_4_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv_5_1 (Conv2D)              (None, 7, 7, 128)    295040      ['relu_4_2[0][0]']               \n",
            "                                                                                                  \n",
            " norm_5_1 (BatchNormalization)  (None, 7, 7, 128)    512         ['conv_5_1[0][0]']               \n",
            "                                                                                                  \n",
            " relu_5_1 (Activation)          (None, 7, 7, 128)    0           ['norm_5_1[0][0]']               \n",
            "                                                                                                  \n",
            " avg_pool_5_1 (AveragePooling2D  (None, 7, 7, 128)   0           ['relu_5_1[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " flat_5_1 (Flatten)             (None, 6272)         0           ['avg_pool_5_1[0][0]']           \n",
            "                                                                                                  \n",
            " fc_5 (Dense)                   (None, 2048)         12847104    ['flat_5_1[0][0]']               \n",
            "                                                                                                  \n",
            " norm_5 (BatchNormalization)    (None, 2048)         8192        ['fc_5[0][0]']                   \n",
            "                                                                                                  \n",
            " relu_5 (Activation)            (None, 2048)         0           ['norm_5[0][0]']                 \n",
            "                                                                                                  \n",
            " drop_5 (Dropout)               (None, 2048)         0           ['relu_5[0][0]']                 \n",
            "                                                                                                  \n",
            " fc_6 (Dense)                   (None, 2048)         4196352     ['drop_5[0][0]']                 \n",
            "                                                                                                  \n",
            " norm_6 (BatchNormalization)    (None, 2048)         8192        ['fc_6[0][0]']                   \n",
            "                                                                                                  \n",
            " relu_6 (Activation)            (None, 2048)         0           ['norm_6[0][0]']                 \n",
            "                                                                                                  \n",
            " drop_6 (Dropout)               (None, 2048)         0           ['relu_6[0][0]']                 \n",
            "                                                                                                  \n",
            " fc_7 (Dense)                   (None, 1)            2049        ['drop_6[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,488,193\n",
            "Trainable params: 21,475,265\n",
            "Non-trainable params: 12,928\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=SGD(lr=0.001),\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "cZa6l-0fO-Zl"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator_aug,\n",
        "                    batch_size=8,\n",
        "                    epochs=20,\n",
        "                    validation_data=val_generator_aug)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p-FHW0iCL7pk",
        "outputId": "6bf2506b-ff36-4789-ba99-117f6bd1458c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "15/15 [==============================] - 37s 2s/step - loss: 0.8461 - accuracy: 0.6957 - val_loss: 0.7066 - val_accuracy: 0.5128\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 9s 625ms/step - loss: 0.7229 - accuracy: 0.6957 - val_loss: 0.6971 - val_accuracy: 0.5128\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 9s 608ms/step - loss: 0.6765 - accuracy: 0.6957 - val_loss: 0.7069 - val_accuracy: 0.5128\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 10s 698ms/step - loss: 0.7042 - accuracy: 0.6957 - val_loss: 0.6988 - val_accuracy: 0.5128\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 10s 669ms/step - loss: 0.7006 - accuracy: 0.6957 - val_loss: 0.6972 - val_accuracy: 0.5128\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 9s 578ms/step - loss: 0.7161 - accuracy: 0.6957 - val_loss: 0.7030 - val_accuracy: 0.5128\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 10s 677ms/step - loss: 0.7612 - accuracy: 0.6957 - val_loss: 0.6964 - val_accuracy: 0.5128\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 10s 686ms/step - loss: 0.6322 - accuracy: 0.6957 - val_loss: 0.7005 - val_accuracy: 0.5128\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 9s 628ms/step - loss: 0.5842 - accuracy: 0.6957 - val_loss: 0.6907 - val_accuracy: 0.5128\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 9s 618ms/step - loss: 0.7097 - accuracy: 0.6957 - val_loss: 0.6942 - val_accuracy: 0.5128\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 10s 687ms/step - loss: 0.6558 - accuracy: 0.6957 - val_loss: 0.7030 - val_accuracy: 0.5128\n",
            "Epoch 12/20\n",
            "15/15 [==============================] - 10s 663ms/step - loss: 0.6390 - accuracy: 0.6957 - val_loss: 0.6925 - val_accuracy: 0.5128\n",
            "Epoch 13/20\n",
            "15/15 [==============================] - 9s 606ms/step - loss: 0.6303 - accuracy: 0.6957 - val_loss: 0.7469 - val_accuracy: 0.5128\n",
            "Epoch 14/20\n",
            "15/15 [==============================] - 10s 701ms/step - loss: 0.5674 - accuracy: 0.6957 - val_loss: 0.6898 - val_accuracy: 0.5128\n",
            "Epoch 15/20\n",
            "15/15 [==============================] - 10s 686ms/step - loss: 0.5540 - accuracy: 0.6957 - val_loss: 0.7467 - val_accuracy: 0.5128\n",
            "Epoch 16/20\n",
            "15/15 [==============================] - 9s 602ms/step - loss: 0.5088 - accuracy: 0.6957 - val_loss: 0.7378 - val_accuracy: 0.5128\n",
            "Epoch 17/20\n",
            "15/15 [==============================] - 10s 648ms/step - loss: 0.6082 - accuracy: 0.6957 - val_loss: 0.6500 - val_accuracy: 0.5128\n",
            "Epoch 18/20\n",
            "15/15 [==============================] - 10s 700ms/step - loss: 0.5955 - accuracy: 0.6957 - val_loss: 0.7740 - val_accuracy: 0.5128\n",
            "Epoch 19/20\n",
            "15/15 [==============================] - 12s 820ms/step - loss: 0.6076 - accuracy: 0.6957 - val_loss: 0.7821 - val_accuracy: 0.5128\n",
            "Epoch 20/20\n",
            "15/15 [==============================] - 9s 615ms/step - loss: 0.5924 - accuracy: 0.6957 - val_loss: 0.9186 - val_accuracy: 0.5128\n"
          ]
        }
      ]
    }
  ]
}